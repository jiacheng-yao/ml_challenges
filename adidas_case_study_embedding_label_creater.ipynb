{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('list_articles.txt', 'rb') as f:\n",
    "    list_articles = pickle.load(f)\n",
    "\n",
    "with open('list_productgroup.txt', 'rb') as f:\n",
    "    list_productgroup = pickle.load(f)\n",
    "\n",
    "with open('list_category.txt', 'rb') as f:\n",
    "    list_category = pickle.load(f)\n",
    "\n",
    "with open('list_sizes.txt', 'rb') as f:\n",
    "    list_sizes = pickle.load(f)\n",
    "    \n",
    "list_country = [\"Germany\", \"France\", \"Austria\"]\n",
    "\n",
    "list_promo1 = [\"0\", \"1\"]\n",
    "\n",
    "list_promo2 = [\"0\", \"1\"]\n",
    "\n",
    "list_style = [\"wide\", \"slim\", \"regular\"]\n",
    "\n",
    "list_gender = [\"unisex\", \"kids\", \"female\", \"male\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use the same LOG_DIR where you stored your checkpoint.\n",
    "LOG_DIR = '/home/jc/workspace/adidas_take_home/tmp_model_dir/'\n",
    "\n",
    "# write labels\n",
    "with open('{}/metadata_article.tsv'.format(LOG_DIR), 'w') as f:\n",
    "    for word in list_articles:\n",
    "        f.write(word + '\\n')\n",
    "\n",
    "with open('{}/metadata_productgroup.tsv'.format(LOG_DIR), 'w') as f:\n",
    "    for word in list_productgroup:\n",
    "        f.write(word + '\\n')\n",
    "\n",
    "with open('{}/metadata_category.tsv'.format(LOG_DIR), 'w') as f:\n",
    "    for word in list_category:\n",
    "        f.write(word + '\\n')\n",
    "\n",
    "with open('{}/metadata_sizes.tsv'.format(LOG_DIR), 'w') as f:\n",
    "    for word in list_sizes:\n",
    "        f.write(word + '\\n')\n",
    "\n",
    "with open('{}/metadata_country.tsv'.format(LOG_DIR), 'w') as f:\n",
    "    for word in list_country:\n",
    "        f.write(word + '\\n')\n",
    "\n",
    "with open('{}/metadata_promo1.tsv'.format(LOG_DIR), 'w') as f:\n",
    "    for word in list_promo1:\n",
    "        f.write(word + '\\n')\n",
    "\n",
    "with open('{}/metadata_promo2.tsv'.format(LOG_DIR), 'w') as f:\n",
    "    for word in list_promo2:\n",
    "        f.write(word + '\\n')\n",
    "\n",
    "with open('{}/metadata_style.tsv'.format(LOG_DIR), 'w') as f:\n",
    "    for word in list_style:\n",
    "        f.write(word + '\\n')\n",
    "\n",
    "with open('{}/metadata_gender.tsv'.format(LOG_DIR), 'w') as f:\n",
    "    for word in list_gender:\n",
    "        f.write(word + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/jc/workspace/adidas_take_home/model_dir/model.ckpt-24600\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers.python import ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops.metrics import mean\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.import_meta_graph('model_dir/model.ckpt-24600.meta')\n",
    "    # Restore latest checkpoint\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('model_dir/'))\n",
    "    # Initalize the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Get default graph (supply your custom graph if you have one)\n",
    "    graph = tf.get_default_graph()\n",
    "\n",
    "    # It will give tensor object\n",
    "    article_embedding = graph.get_tensor_by_name('dnn/input_from_feature_columns/article_embedding/weights/part_0:0')\n",
    "    category_embedding = graph.get_tensor_by_name('dnn/input_from_feature_columns/category_embedding/weights/part_0:0')\n",
    "    country_embedding = graph.get_tensor_by_name('dnn/input_from_feature_columns/country_embedding/weights/part_0:0')\n",
    "    gender_embedding = graph.get_tensor_by_name('dnn/input_from_feature_columns/gender_embedding/weights/part_0:0')\n",
    "    productgroup_embedding = graph.get_tensor_by_name('dnn/input_from_feature_columns/productgroup_embedding/weights/part_0:0')\n",
    "    promo1_embedding = graph.get_tensor_by_name('dnn/input_from_feature_columns/promo1_embedding/weights/part_0:0')\n",
    "    promo2_embedding = graph.get_tensor_by_name('dnn/input_from_feature_columns/promo2_embedding/weights/part_0:0')\n",
    "    sizes_embedding = graph.get_tensor_by_name('dnn/input_from_feature_columns/sizes_embedding/weights/part_0:0')\n",
    "    style_embedding = graph.get_tensor_by_name('dnn/input_from_feature_columns/style_embedding/weights/part_0:0')\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    # create a TensorFlow summary writer\n",
    "    summary_writer = tf.summary.FileWriter(LOG_DIR)\n",
    "    config = projector.ProjectorConfig()\n",
    "    embedding_conf = config.embeddings.add()\n",
    "    embedding_conf.tensor_name = article_embedding.name\n",
    "    embedding_conf.metadata_path = os.path.join(LOG_DIR, 'metadata_article.tsv')\n",
    "    \n",
    "    embedding_conf2 = config.embeddings.add()\n",
    "    embedding_conf2.tensor_name = category_embedding.name\n",
    "    embedding_conf2.metadata_path = os.path.join(LOG_DIR, 'metadata_category.tsv')\n",
    "    \n",
    "    projector.visualize_embeddings(summary_writer, config)\n",
    "\n",
    "#     # save the model\n",
    "    saver2 = tf.train.Saver()\n",
    "#     saver2.save(sess, os.path.join(LOG_DIR, \"model.ckpt\"))\n",
    "    saver2.save(sess, os.path.join(LOG_DIR, \"model.ckpt\"), global_step=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor_name: \"dnn/input_from_feature_columns/article_embedding/weights/part_0:0\"\n",
       "metadata_path: \"/home/jc/workspace/adidas_take_home/tmp_model_dir/metadata_article.tsv\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor_name: \"dnn/input_from_feature_columns/category_embedding/weights/part_0:0\"\n",
       "metadata_path: \"/home/jc/workspace/adidas_take_home/tmp_model_dir/metadata_category.tsv\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_conf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
